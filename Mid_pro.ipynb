{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e5a52b",
   "metadata": {},
   "source": [
    "## import 칸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbb4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 모듈\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") # 엑셀 파일 불러오때 심플 오류 무시하는 기능"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66a88bcb",
   "metadata": {},
   "source": [
    "## 5대 범죄현황, folium 데이터 처리, 전처리 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7761d907",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>자치구별</th>\n",
       "      <th>발생 / 검거</th>\n",
       "      <th>수치</th>\n",
       "      <th>연도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>종로구</td>\n",
       "      <td>발생</td>\n",
       "      <td>5021.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>중구</td>\n",
       "      <td>발생</td>\n",
       "      <td>5231.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>용산구</td>\n",
       "      <td>발생</td>\n",
       "      <td>3799.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>성동구</td>\n",
       "      <td>발생</td>\n",
       "      <td>3582.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>광진구</td>\n",
       "      <td>발생</td>\n",
       "      <td>6268.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>관악구</td>\n",
       "      <td>검거</td>\n",
       "      <td>3858.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>서초구</td>\n",
       "      <td>검거</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>강남구</td>\n",
       "      <td>검거</td>\n",
       "      <td>5245.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>송파구</td>\n",
       "      <td>검거</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>강동구</td>\n",
       "      <td>검거</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    자치구별 발생 / 검거      수치    연도\n",
       "1    종로구      발생  5021.0  2014\n",
       "2     중구      발생  5231.0  2014\n",
       "3    용산구      발생  3799.0  2014\n",
       "4    성동구      발생  3582.0  2014\n",
       "5    광진구      발생  6268.0  2014\n",
       "..   ...     ...     ...   ...\n",
       "359  관악구      검거  3858.0  2020\n",
       "360  서초구      검거  3052.0  2020\n",
       "361  강남구      검거  5245.0  2020\n",
       "362  송파구      검거  3544.0  2020\n",
       "363  강동구      검거  2662.0  2020\n",
       "\n",
       "[350 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로우데이터 파일 불러오기\n",
    "# 애초에 데이터를 많이 가공한 상태로 가져오면 수고를 덜 수 있음\n",
    "df_1 = pd.read_excel(\"5대+범죄+발생현황_20221021174201.xlsx\")\n",
    "# 범위 밖에 있는 데이터를 지우기 위한 컬럼 및 인덱스 작업\n",
    "# dr_col = [\"2013\", \"2013.1\", \"2013.2\", \"2013.3\", \n",
    "#           \"2013.4\", \"2013.5\", \"2013.6\", \"2013.7\", \n",
    "#           \"2013.8\", \"2013.9\", \"2013.10\", \"2013.11\"] #더 편한 방법은 없을까?\n",
    "# df_1 = df_1.drop(columns = dr_col)\n",
    "df_1 = df_1.drop(columns = \"자치구별(1)\", index = 0)\n",
    "\n",
    "# 로우데이터에서 강간과 강제추행의 데이터만 가져오기 위한 작업\n",
    "# 2010.*에서 *의 숫자만 바꿔주면 데이터 변형 가능\n",
    "# 하지만 2020.10 데이터는 다른 방식으로 접근해야함 (float이 적용이 되지 않음)\n",
    "\n",
    "y_sum = []\n",
    "for x in range(7):\n",
    "    yn = x + 4\n",
    "    yy = str(2010 + int(yn))\n",
    "    yy_1 = str(2010.1 + int(yn))\n",
    "    y_sum.append(yy)\n",
    "    y_sum.append(yy_1)\n",
    "\n",
    "# str()을 사용하면 숫자를 문자열로 변경 가능\n",
    "# str(y_sum)\n",
    "\n",
    "# y_sum에 처음 인덱스에 \"자치구별(2)\"를 넣어주고 형식을 맞춘 후에\n",
    "# df_1에 해당 컬럼값만 가져오게 하는 방법\n",
    "y_sum.insert(0, \"자치구별(2)\")\n",
    "df_2 = df_1[y_sum]\n",
    "\n",
    "# 컬럼명을 정리하고 필요없는 인덱스는 드랍하고 리 인덱싱 작업\n",
    "df_2.columns = [\"자치구별\", \"2014년_발생\", \"2014년_검거\", \n",
    "                \"2015년_발생\", \"2015년_검거\", \"2016년_발생\", \"2016년_검거\", \n",
    "                \"2017년_발생\", \"2017년_검거\", \"2018년_발생\", \"2018년_검거\", \n",
    "                \"2019년_발생\", \"2019년_검거\", \"2020년_발생\", \"2020년_검거\"]\n",
    "df_2 = df_2.drop(index = 1)\n",
    "df_2 = df_2.drop(index = 2)\n",
    "df_2 = df_2.reset_index(drop = True)\n",
    "\n",
    "# melt를 이용하여 데이터를 시각화하기에 좋도록 정리\n",
    "df_3 = df_2.melt(id_vars = \"자치구별\", value_vars = df_2.columns[1:], \n",
    "                 value_name = \"수치\", var_name = \"발생 / 검거\")\n",
    "\n",
    "# 파생변수를 만듬 (연도와 발생 / 검거에 대한 파생변수)\n",
    "df_3[\"연도\"] = pd.to_numeric(df_3[\"발생 / 검거\"].str[:4], errors = 'coerce')\n",
    "df_3[\"발생 / 검거\"] = df_3[\"발생 / 검거\"].str[6:]\n",
    "\n",
    "# 그룹바이 하여 한눈에 파악하기 쉽게 처리 가능\n",
    "df_4 = df_3.groupby([\"연도\", \"자치구별\", \"발생 / 검거\"])[[\"수치\"]].mean()\n",
    "\n",
    "# 소계가 있는 인덱스를 모두 드랍하는 방법\n",
    "dr_ind = df_3[df_3[\"자치구별\"] == \"소계\"].index\n",
    "df_5 = df_3.drop(dr_ind)\n",
    "df_5\n",
    "\n",
    "# plotly histogram 시각화\n",
    "# 단점은 facet_col을 사용하면 자치구별이 모두 보이지 않음\n",
    "# !!! 그룹바이 한 값은 row가 하나로 잡히기 때문에 시각화 데이터로 쓰기가 매우 어렵다.\n",
    "# 시각화 데이터로 사용이 용이한것은 melt한 데이터들이다.\n",
    "# px.histogram(df_5, x = \"자치구별\", y = \"수치\", color = \"발생 / 검거\", histfunc = \"avg\")\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "import folium\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") # 엑셀 파일 불러오때 심플 오류 무시하는 기능\n",
    "\n",
    "\n",
    "# 지도에 기본 설정으로 찍힐 좌표를 설정하는 단계\n",
    "# 결과 첫 화면 위치가 된다.\n",
    "# location 에는 위도와 경도를 zoom start는 지정한 좌표에서 얼마나 확대된 화면이 출력되는 지를 지정하는 것, 범위는 0 ~ 18\n",
    "# width 와 height 옵션도 있어서 지도의 크기 설정이 가능하다.\n",
    "# title 의 디폴트 값은 OpenStreetMap이며, Stamen Toner와 cartodbpositron가 있다.\n",
    "m = folium.Map(location = [37.56624759994501, 126.978844845852], zoom_start = 11, tiles=\"OpenStreetMap\")\n",
    "\n",
    "\n",
    "# 파일로 저장하기 위해서는 m.save((\"경로/파일명.html\")) 을 통해서 가능하다.\n",
    "# 경로는 따로 설정하지 않으면 해당 파이썬 파일이 저장된 폴더로 디폴트 값되며, 기본 툴은 구글 맵으로 지정된다.\n",
    "# m.save((\"foli_map_ex.html\")) -- 왼쪽 코드를 통해 파일 저장이 가능하다.\n",
    "\n",
    "# 서울 행정구역 json raw파일(githubcontent)\n",
    "# 변수로 requests 값 지정하기\n",
    "r = requests.get('https://raw.githubusercontent.com/southkorea/seoul-maps/master/kostat/2013/json/seoul_municipalities_geo_simple.json')\n",
    "c = r.content\n",
    "\n",
    "# json 모듈을 사용하여 html 형식의 데이터로 변경하기\n",
    "seoul_geo = json.loads(c)\n",
    "\n",
    "# json을 통해서 boundary를 표현하는 코드\n",
    "# folium.GeoJson(data값(디폴트 값으로 그냥 데이터 값만 넣어도 출력됨), name = \"해당 boundry의 이름\")\n",
    "folium.GeoJson(seoul_geo, name='지역구').add_to(m)\n",
    "\n",
    "# 처리된 데이터를 불러오기\n",
    "df = pd.read_excel(\"강간추행_데이터후처리파일.xlsx\")\n",
    "# 데이터의 형식이 궁금하다면 head를 통해 확인\n",
    "# df.head()\n",
    "\n",
    "# 자치구별의 이름을 넣었을 때, 해당 수치를 전부 더한값을 구해주는 함수 만들기\n",
    "def de_sum(x):\n",
    "    gu_sum = df[df[\"자치구별\"] == x][\"수치\"].sum()\n",
    "    return gu_sum\n",
    "\n",
    "# 자치구별 컬럼 안에 중복치 아닌 값들을 전부 모아서 list 형식화\n",
    "gu_list = list(df[\"자치구별\"].unique())\n",
    "\n",
    "# 딕셔너리 컨프리헨션을 통해 자치구와 de_sum 함수값들을 딕셔너리 형식화\n",
    "gu_dict = {x : de_sum(x) for x in gu_list}\n",
    "\n",
    "# 딕셔너리를 시리즈 변형하면 key 값은 인덱스로 value 값은 해당 value 값으로 변형된다.\n",
    "gu_dict_sz = pd.Series(gu_dict)\n",
    "\n",
    "\n",
    "# bins = list(gu_dict_sz.quantile([0, 0.25, 0.5, 0.75, 1]))\n",
    "# bins 는 알아서 추가가 되었다? -- 공식 문서를 확인하고 추가 학습이 필요함\n",
    "\n",
    "# 4분위수에 의한 색깔로 맵 표현하기\n",
    "# 다른 parameter 들을 추가 학습이 필요함 / 공식 문서를 참고해야 함\n",
    "m.choropleth(geo_data=seoul_geo,\n",
    "             data=gu_dict_sz, \n",
    "             fill_color='YlOrRd', # 색상 변경도 가능하다\n",
    "             fill_opacity=0.5,\n",
    "             line_opacity=0.2,\n",
    "             key_on='properties.name',\n",
    "             legend_name=\"지역구별 강간, 강제추행 발생수 (2014~2020년도)\")\n",
    "\n",
    "# 원하는 좌표가 입력되있는 좌표 데이터 불러오기\n",
    "seo_map = pd.read_excel(\"서울시_좌표.xlsx\")\n",
    "\n",
    "# 이전에 만들었던 자치구별 해당 범죄 발생수 데이터를 사용\n",
    "# \"자치구별\"과 \"발생수\"라는 컬럼을 만들어 주기 위해 key 값으로 배정함\n",
    "A = list(gu_dict.keys())\n",
    "B = list(gu_dict.values())\n",
    "gu_df = {\"자치구별\" : A, \"발생수\" : B}\n",
    "\n",
    "# 위에서 만든 딕셔너리를 DataFrame 형식화\n",
    "# columns = [\"자치구별\", \"발생수\"]\n",
    "gu_df2 = pd.DataFrame(gu_df)\n",
    "\n",
    "# 위 데이터와 서울시 좌표 데이터를 merge를 통해 합치기\n",
    "# \"on\" parameter를 이용해서 \"자치구별\" 값이 맞아 떨어지도록 지정\n",
    "gu_mer = pd.merge(left = gu_df2, right = seo_map, on = \"자치구별\")\n",
    "\n",
    "\n",
    "# 맵에 숫자로 표시하는 기능(MarkerCluster() 메서드를 사용)\n",
    "# from folium.plugins import MarkerCluster 모듈을 실행시켜야 함\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "for lat, long in zip(gu_mer[\"위도\"], gu_mer[\"경도\"]):\n",
    "    folium.Marker([lat, long], tooltip = gu_mer[gu_mer[\"위도\"] == lat][[\"자치구별\", \"발생수\"]], icon = folium.Icon(color=\"green\")).add_to(marker_cluster)\n",
    "   \n",
    "\"\"\"\n",
    "tooltip =\n",
    "f'Accepted<br />\n",
    "Name: {df.iloc[i,0]}<br />\n",
    "Cost: {df.iloc[i,3]:,.0f}<br /> \n",
    "Category: {df.iloc[i,4]}<br />\n",
    "Distance: {np.round(df.iloc[i,6],2)}(m)<br />\n",
    "Call payment: {df.iloc[i,5]}',\n",
    "\n",
    "위 지도에서 좌표에 순수히 값만 나오게 하는 코드라 했지만, 이해를 못해서 우선 메모를 해둠\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65f7767a",
   "metadata": {},
   "source": [
    "## 5대 범죄현황, 도로 시설물, 전처리 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ed7e3c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '5대+범죄+발생현황_20221021174201.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#엑셀파일 불러오기\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5대+범죄+발생현황_20221021174201.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 행 제거\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '5대+범죄+발생현황_20221021174201.csv'"
     ]
    }
   ],
   "source": [
    "#엑셀파일 불러오기\n",
    "df = pd.read_csv(\"5대+범죄+발생현황_20221019163055.csv\")\n",
    "\n",
    "# 행 제거\n",
    "df = df.drop([0,1,2,3],axis=0)\n",
    "\n",
    "#이름 변경하기\n",
    "df = df.rename(columns = {\"자치구별(2)\":\"자치구별\"})\n",
    "\n",
    "df = df.melt(id_vars = \"자치구별\", value_vars = df.columns[1:], value_name = \"건수\", var_name = \"년도\")\n",
    "\n",
    "df[\"건수\"].replace('-',np.nan,inplace=True)\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "df[\"건수\"] = df[\"건수\"].astype(\"int\")\n",
    "\n",
    "df[\"년\"] = df[\"년도\"].map(lambda x : int(x.split(\".\")[0]))\n",
    "df[\"코드\"] = df[\"년도\"].map(lambda x : int(x.split(\".\")[1]))\n",
    "\n",
    "kill_dict = {2: \"발생\", 3 :\"검거\"}\n",
    "df[\"발생검거\"] = df[\"코드\"].map(kill_dict)\n",
    "\n",
    "px.histogram(df, x =\"건수\", y =\"자치구별\",histfunc= \"sum\",color = \"발생검거\",barmode=\"group\")\n",
    "\n",
    "px.histogram(df,x = \"건수\", y=\"자치구별\",histfunc=\"sum\",color =\"발생검거\",facet_col =\"발생검거\")\n",
    "\n",
    "plt.figure(figsize =(20,7))\n",
    "sns.pointplot(data = df , x = \"자치구별\" ,y = \"건수\")\n",
    "\n",
    "#발생검거 중 발생만 가져오기\n",
    "df_C = df[df[\"발생검거\"]==\"발생\"]\n",
    "df_C.tail()\n",
    "\n",
    "data_1 = df_C[df_C[\"년\"] == 2014]\n",
    "data_2 = df_C[df_C[\"년\"] == 2015]\n",
    "data_3 = df_C[df_C[\"년\"] == 2016]\n",
    "data_4 = df_C[df_C[\"년\"] == 2017]\n",
    "data_5 = df_C[df_C[\"년\"] == 2018]\n",
    "data_6 = df_C[df_C[\"년\"] == 2019]\n",
    "data_7 = df_C[df_C[\"년\"] == 2020]\n",
    "\n",
    "co_1 = data_1[\"건수\"].sum()\n",
    "co_2 = data_2[\"건수\"].sum()\n",
    "co_3 = data_3[\"건수\"].sum()\n",
    "co_4 = data_4[\"건수\"].sum()\n",
    "co_5 = data_5[\"건수\"].sum()\n",
    "co_6 = data_6[\"건수\"].sum()\n",
    "co_7 = data_7[\"건수\"].sum()\n",
    "\n",
    "n_1 = data_1[\"건수\"] / co_1 * 100 \n",
    "n_2 = data_2[\"건수\"] / co_2 * 100 \n",
    "n_3 = data_3[\"건수\"] / co_3 * 100 \n",
    "n_4 = data_4[\"건수\"] / co_4 * 100\n",
    "n_5 = data_5[\"건수\"] / co_5 * 100\n",
    "n_6 = data_6[\"건수\"] / co_6 * 100\n",
    "n_7 = data_7[\"건수\"] / co_7 * 100\n",
    "\n",
    "total = pd.concat([n_1,n_2,n_3,n_4,n_5,n_6,n_7])\n",
    "\n",
    "total = total.rename(\"연도별 발생건수 백분율\")\n",
    "\n",
    "total_3 = pd.DataFrame(total)\n",
    "\n",
    "df_A = pd.concat([df_C,total_3], axis =1)\n",
    "\n",
    "pe = pd.read_csv(\"person.csv\",encoding = \"cp949\")\n",
    "\n",
    "pe = pe.drop(\"Unnamed: 0\",axis =1)\n",
    "\n",
    "df_join11 = pd.merge(df_A, pe, how='outer',  on=\"자치구별\")\n",
    "\n",
    "df_last = df_join11[[\"자치구별\",\"생활인구 대비 폭력\"]]\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.barplot(data=df_last.sort_values(\"생활인구 대비 폭력\", ascending=False), x=\"자치구별\", y = \"생활인구 대비 폭력\")\n",
    "\n",
    "---------------------------------------------------------\n",
    "\n",
    "#데이터 불러오기\n",
    "crime = pd.read_excel(\"5_20221018192142.xlsx\",engine = \"openpyxl\")\n",
    "crime.head(4)\n",
    "# 데이터 크기 확인\n",
    "crime.shape\n",
    "#데이터 기본 정보 출력\n",
    "crime.info()\n",
    "#데이터 기술 통계 정보 요약\n",
    "crime.describe()\n",
    "# 고유값 개수\n",
    "crime.value_counts()\n",
    "#누락데이터 찾기\n",
    "crime.isnull().sum().sum()\n",
    "crime.columns\n",
    "# 행 삭제 하기\n",
    "crime = crime.drop([\"장소별(1)\",\"범죄별(1)\",\"범죄별(2)\",\"2012\",\"2013\",\"2021\"],axis=1)\n",
    "#일부 데이터 보기\n",
    "crime.head(4)\n",
    "# 행 삭제하기\n",
    "crime = crime.drop([0,1,2,3,4,5],axis =0)\n",
    "crime.head(5)\n",
    "#결측지 값 제거\n",
    "crime=crime.dropna()\n",
    "#타입바꾸기\n",
    "crime[\"연도\"] = crime[\"연도\"].astype(\"int\")\n",
    "crime[\"발생건수\"] = crime[\"발생건수\"].astype(\"int\")\n",
    "#타입 확인하기\n",
    "crime.info()\n",
    "#시각화\n",
    "px.histogram(crime, x = \"발생건수\", y =\"장소\", histfunc='sum',title=\"장소별 발생건수\")\n",
    "crime_year = crime.groupby([\"연도\",\"장소\"])[\"발생건수\"].mean().unstack()\n",
    "crime_year[[\"노상\",\"단독주택\",\"상점\",\"유흥접객업소\"]].plot(kind = \"bar\",figsize = (15,8),title=\"년도별 장소에 따른,범죄 증감률\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da56369a",
   "metadata": {},
   "source": [
    "## 5대 범죄현황, 고위험 음주율, 전처리 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 폭행 범죄 발생 데이터\n",
    "# 1) 데이터를 불러와 쓸모 없는 열과 컬럼 제거\n",
    "# * 2014 ~ 2020 컬럼을 제거한 것은 범죄 발생 합계 수치가 들어있는 컬럼이였기 때문\n",
    "df_5crime = pd.read_csv(glob(\"data\\\\5대범죄*.csv\")[1])\n",
    "df_5crime = df_5crime.drop(columns=\"자치구별(1)\", index=0)\n",
    "df_5 = df_5crime.drop(columns=[\"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"], index=[1, 2, 3])\n",
    "\n",
    "# 2) 컬럼에 연도와 범죄 분류코드가 합쳐져 있어 melt로 데이터를 녹임\n",
    "df_5m = df_5.melt(id_vars=\"자치구별(2)\", var_name=\"연+분류\", value_name=\"건수\")\n",
    "\n",
    "# 3) apply(lambda x : x.split(“.”)) 함수를 사용해 연도와 범죄 분류를 분리하여 \n",
    "# 각각 연도와 분류코드 컬럼으로 넣어줌\n",
    "df_5m[\"연도\"] = df_5m[\"연+분류\"].apply(lambda x : int(x.split(\".\")[0]))\n",
    "df_5m[\"분류코드\"] = df_5m[\"연+분류\"].apply(lambda x : int(x.split(\".\")[1]))\n",
    "\n",
    "# 4) 범죄 분류 코드별 범죄명을 딕셔너리에 넣어주고 map 함수로 매칭하여 \n",
    "# 범죄 분류 코드를 ‘범죄명-발생’, ‘범죄명-검거’로 변환\n",
    "crime_code =\"\"\"1 합계-검거\n",
    "2 살인-발생\n",
    "3 살인-검거\n",
    "4 강도-발생\n",
    "5 강도-검거\n",
    "6 강간,강제추행-발생\n",
    "7 강간,강제추행-검거\n",
    "8 절도-발생\n",
    "9 절도-검거\n",
    "10 폭력-발생\n",
    "11 폭력-검거\"\"\"\n",
    " \n",
    "code_list = crime_code.split(\"\\n\")\n",
    "code_dict = {int(n.split()[0]) : n.split()[1] for n in code_list}\n",
    "df_5m[\"분류\"] = df_5m[\"분류코드\"].map(code_dict)\n",
    "\n",
    "# 5) 분류 코드를 다시 분리하여 범죄종류와 발생/검거 컬럼으로 넣어줌\n",
    "df_5m[\"범죄종류\"] = df_5m[\"분류\"].apply(lambda x : x.split(\"-\")[0])\n",
    "df_5m[\"발생/검거\"] = df_5m[\"분류\"].apply(lambda x : x.split(\"-\")[1])\n",
    "\n",
    "# 6) 범죄종류 중 폭력인 것을 가져와 새 데이터프레임으로 저장\n",
    "df_hit = df_5m[df_5m[\"범죄종류\"]==\"폭력\"]\n",
    "\n",
    "# 7) 폭력 범죄 데이터프레임에서 \"발생/검거\" 컬럼의 값이 \"발생\"인 데이터만 가져와 \n",
    "# groupby를 통해 자치구별 연평균 발생 건수만 저장함\n",
    "hit_mean = round(df_hit[df_hit[\"발생/검거\"]==\"발생\"].groupby(by=[\"자치구별\"])[\"건수\"].mean(), 2)\n",
    "\n",
    "\n",
    "# 2. 고위험 음주율 데이터\n",
    "# 1)데이터 로드하기\n",
    "df_drink = pd.read_csv('data\\\\고위험+음주율_20221019142156.csv')\n",
    "\n",
    "# 2)데이터 컬럼 및 인덱스 정리\n",
    "df_drink = df_drink.drop(columns=[\"구분별(1)\", \"구분별(2)\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"], index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "df_drink_all = df_drink.drop(columns=[\"구분별(1)\", \"구분별(2)\"], index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "df_drink_all = df_drink_all[[\"구분별(3)\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]]\n",
    "df_drink_all = df_drink_all.rename(columns={\"구분별(3)\" : \"자치구별\"})\n",
    "df_drink_all = df_drink_all.reset_index(drop=True)\n",
    "\n",
    "# 3)melt로 데이터 녹여주기\n",
    "df_drink_m = df_drink_all.melt(id_vars=\"자치구별\", var_name=\"연도\", value_name=\"음주율\")\n",
    "\n",
    "# 4)연도, 음주율 컬럼의 데이터 타입 바꿔주기\n",
    "df_drink_m[\"연도\"] = df_drink_m[\"연도\"].astype(int)\n",
    "df_drink_m[\"음주율\"] = df_drink_m[\"음주율\"].astype(float)\n",
    "\n",
    "# 5)groupby를 통해 자치구별 연 평균 수치 구해주기\n",
    "drink_mean = df_drink_m.groupby(\"자치구별\")[\"음주율\"].mean().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# 3. 유흥주점 개수\n",
    "# 1) 데이터 로드\n",
    "df_sul = pd.read_csv('data\\\\서울시 유흥주점영업 인허가 정보.csv', encoding=\"cp949\")\n",
    "\n",
    "# 2) 정상 영업 중인 유흥주점 데이터만 가져오기\n",
    "df_bar = df_sul[df_sul[\"영업상태명\"] == \"영업/정상\"]\n",
    "\n",
    "# 3) 결측치 제거\n",
    "df_baraddress = df_bar[\"지번주소\"].dropna()\n",
    "\n",
    "# 4) 지번주소에서 자치구 데이터만 뽑아오기\n",
    "df_baraddress = df_baraddress.apply(lambda x : x.split(\" \")[1])\n",
    "\n",
    "# 5) 자치구별 유흥주점 개수를 count하여 저장\n",
    "df_bar_gu = df_baraddress.value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14fb07b8",
   "metadata": {},
   "source": [
    "## 5대 범죄현황, CCTV 데이터, 생활인구 데이터, 전처리 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범죄 발생/검거 데이터(절도)\n",
    "# 1) raw 데이터에서 필요 없는 index와 column 제거 및 column명 재설정\n",
    "df = pd.read_csv(\"/Users/sangu/likelion_AIS/ais7/mid_project/mid_data/14~절도.csv\")\n",
    "df = df.drop([0,1,2,3],axis=0)\n",
    "df = df.rename(columns = {\"자치구별(2)\" : \"자치구\"})\n",
    "df = df.rename(columns = {\"2014\": \"2014.1\", \"2014.1\": \"2014.2\", \"2015\" : \"2015.1\", '2015.1' : \"2015.2\" ,'2016':\"2016.1\", '2016.1':\"2016.2\" ,'2017': \"2017.1\", '2017.1': \"2017.2 \",'2018': \"2018.1\" ,'2018.1': \"2018.2\" ,'2019': \"2019.1\", '2019.1': \"2019.2\", '2020': '2020.1', '2020.1': '2020.2', '2021': '2021.1', '2021.1': '2021.2'})\n",
    "\n",
    "# 2) melt 사용해서 데이터 보기 쉽게 바꾸기\n",
    "df = df.melt(id_vars = \"자치구\", value_vars = df.columns[1:], value_name = \"사건수\", var_name = \"년도\")\n",
    "\n",
    "# 3) 년도 column을 만들고 코드를 통해 발생과 검거를 나누는 column을 만듬\n",
    "df[\"년\"] = df[\"년도\"].map(lambda x : int(x.split(\".\")[0]))\n",
    "df[\"코드\"] = df[\"년도\"].map(lambda x : int(x.split(\".\")[1]))\n",
    "kill = {1: \"발생\", 2 :\"검거\"}\n",
    "df[\"발생검거\"] = df[\"코드\"].map(kill)\n",
    "\n",
    "# 4) 시각화\n",
    "# 4-1) column타입 변환하기\n",
    "df[\"사건수\"] = df[\"사건수\"].astype(int)\n",
    "plt.figure(figsize = (20,12))\n",
    "sns.barplot(data = df, x= \"자치구\", y = \"사건수\", hue = \"발생검거\")\n",
    "# sort_values()\n",
    "sort_df = df.sort_values(\"사건수\", ascending = False)\n",
    "plt.figure(figsize = (20,12))\n",
    "sns.barplot(data = sort_df, x= \"자치구\", y = \"사건수\", hue = \"발생검거\")\n",
    "df[df[\"발생검거\"] == \"발생\"].groupby(\"자치구\")[\"사건수\"].mean().sort_values(ascending = False).plot(kind = \"bar\", figsize = (20,12))\n",
    "\n",
    "# cctv데이터\n",
    "\n",
    "# 1) raw 데이터에서 필요 없는 index와 column 제거 및 column명 재설정\n",
    "cctv = pd.read_csv(\"/Users/sangu/likelion_AIS/ais7/mid_project/mid_data/서울시CCTV설치운영현황(자치구)_연도별_220630기준.csv\", encoding = \"cp949\")\n",
    "cctv = cctv.drop(columns = {\"2013년 이전\\n설치된 CCTV\"})\n",
    "cctv = cctv.rename(columns = {\"구분\": \"자치구\"})\n",
    "cctv = cctv.drop([0])\n",
    "\n",
    "# 2) melt 사용해서 데이터 보기 쉽게 바꾸기\n",
    "cctv = cctv.melt(id_vars = \"자치구\",value_vars = cctv.columns[2:], value_name = \"cctv수\", var_name = \"년도\")\n",
    "\n",
    "# 3) 년도의 oooo\"년\" 년 빼기\n",
    "cctv[\"년도\"] = cctv[\"년도\"].map(lambda x: x.replace(\"년\", \"\"))\n",
    "cctv[\"년도\"].astype(int)\n",
    "\n",
    "# 4) 범죄발생 수와 cctv concat\n",
    "gangnam_cc = cctv[cctv[\"자치구\"] == \"강남구\"]\n",
    "gangnam_cc = gangnam_cc.reset_index(drop = True).drop([0]).reset_index(drop = True)\n",
    "gangnam_event = gangnam[[\"사건수\"]]\n",
    "gangnam_event = gangnam_event.reset_index(drop = True)\n",
    "concat_gangnam = pd.concat([gangnam_cc, gangnam_event], axis = 1)\n",
    "\n",
    "# 전체 cctv 개수 보기\n",
    "sort_cctv = cctv.sort_values(\"총계\", ascending = False)\n",
    "# 전체 cctv 개수\n",
    "sort_cctv.plot(kind = \"bar\")\n",
    "\n",
    "# 5) 시각화\n",
    "fig = plt.figure(figsize=(10,6)) ## 캔버스 생성\n",
    "fig.set_facecolor('white') ## 캔버스 색상 설정\n",
    "ax = fig.add_subplot() ## 그림 뼈대(프레임) 생성\n",
    " \n",
    "ax.plot(concat_gangnam['년도'],concat_gangnam['사건수']) ## 선그래프 생성\n",
    "\n",
    "plt.xticks(rotation=45) ## x축 눈금 라벨 설정 - 40도 회전 \n",
    "plt.title('사건수',fontsize=20) ## 타이틀 설정\n",
    "\n",
    "fig = plt.figure(figsize=(10,5)) ## 캔버스 생성\n",
    "fig.set_facecolor('white') ## 캔버스 색상 설정\n",
    "ax_2 = ax.twinx() ## 그림 뼈대(프레임) 생성\n",
    " \n",
    "ax.plot(concat_gangnam['년도'],concat_gangnam['cctv수']) ## 선그래프 생성\n",
    "\n",
    "plt.xticks(rotation=45) ## x축 눈금 라벨 설정 - 40도 회전 \n",
    "plt.title('cctv수',fontsize=20) ## 타이틀 설정\n",
    "plt.show()\n",
    "\n",
    "# 생활인구 데이터\n",
    "\n",
    "# 1) raw 데이터 불러오기\n",
    "df_gu = pd.read_csv(\"/Users/sangu/likelion_AIS/ais7/mid_project/mid_data/LOCAL_PEOPLE_GU_2021.csv\", encoding = \"cp949\")\n",
    "\n",
    "# 2) 자치구 코드와 자치구 맵함수 적용하기\n",
    "# gu_list 에 자치구코드 : 자치구 로 묶었다.\n",
    "gu_list = gu.split(\"\\n\")\n",
    "gu_name = {}\n",
    "for gl in gu_list:\n",
    "    key = int(gl.split()[0])\n",
    "    val = gl.split()[1]\n",
    "    gu_name[key] = val\n",
    "df_gu[\"구\"] = df_gu[\"자치구코드\"].map(gu_name)\n",
    "df_gu = df_gu[['기준일ID', '시간대구분', '자치구코드', '구', '총생활인구수', '남자0세부터9세생활인구수', '남자10세부터14세생활인구수','남자15세부터19세생활인구수', '남자20세부터24세생활인구수', '남자25세부터29세생활인구수','남자30세부터34세생활인구수', '남자35세부터39세생활인구수', '남자40세부터44세생활인구수','남자45세부터49세생활인구수', '남자50세부터54세생활인구수', '남자55세부터59세생활인구수','남자60세부터64세생활인구수', '남자65세부터69세생활인구수', '남자70세이상생활인구수', '여자0세부터9세생활인구수','여자10세부터14세생활인구수', '여자15세부터19세생활인구수', '여자20세부터24세생활인구수','여자25세부터29세생활인구수', '여자30세부터34세생활인구수', '여자35세부터39세생활인구수','여자40세부터44세생활인구수', '여자45세부터49세생활인구수', '여자50세부터54세생활인구수','여자55세부터59세생활인구수', '여자60세부터64세생활인구수', '여자65세부터69세생활인구수', '여자70세이상생활인구수']]\n",
    "df_gu[[\"자치구코드\", \"구\"]]\n",
    "\n",
    "# 3) column 삭제하기\n",
    "\n",
    "df_gu = df_gu.drop(columns = {'남자0세부터9세생활인구수', '남자10세부터14세생활인구수','남자15세부터19세생활인구수', '남자20세부터24세생활인구수', '남자25세부터29세생활인구수','남자30세부터34세생활인구수', '남자35세부터39세생활인구수', '남자40세부터44세생활인구수','남자45세부터49세생활인구수', '남자50세부터54세생활인구수', '남자55세부터59세생활인구수','남자60세부터64세생활인구수', '남자65세부터69세생활인구수', '남자70세이상생활인구수', '여자0세부터9세생활인구수','여자10세부터14세생활인구수', '여자15세부터19세생활인구수', '여자20세부터24세생활인구수','여자25세부터29세생활인구수', '여자30세부터34세생활인구수', '여자35세부터39세생활인구수','여자40세부터44세생활인구수', '여자45세부터49세생활인구수', '여자50세부터54세생활인구수','여자55세부터59세생활인구수', '여자60세부터64세생활인구수', '여자65세부터69세생활인구수', '여자70세이상생활인구수'})\n",
    "\n",
    "# 4) 총생활인구수 컬럼 전처리하기\n",
    "# 구별로 총생활인구수의 평균값 구하기\n",
    "df_gu[\"총생활인구수\"] = df_gu[\"총생활인구수\"].astype(int)\n",
    "test = list(df_gu[\"구\"].unique())\n",
    "\n",
    "test_2 = []\n",
    "for x in test:\n",
    "    test_1 = df_gu[df_gu[\"구\"] == x][\"총생활인구수\"].mean()\n",
    "    test_2.append((test_1))\n",
    "person = pd.DataFrame(data = list(zip(test,test_2)), columns = [\"구\", \"총생활인구수\"])\n",
    "person[\"총생활인구수\"] = person[\"총생활인구수\"].astype(float).round(1)\n",
    "person[\"총생활인구수\"] = person[\"총생활인구수\"].astype(int)\n",
    "\n",
    "# csv 저장\n",
    "person.to_csv(\"person.csv\", encoding=\"cp949\")\n",
    "# person < 생활인구\n",
    "\n",
    "# 5) sort_values()\n",
    "sort_person = person.sort_values(\"총생활인구수\", ascending = False)\n",
    "\n",
    "\n",
    "# 은영님 가로등 데이터에 인구수, 밀도 넣기\n",
    "\n",
    "# 1) raw 데이터에서 필요 없는 index와 column 제거 및 column명 재설정\n",
    "area_df = pd.read_csv(\"/Users/sangu/Downloads/행정구역별・지목별_국토이용현황_시군구_20221021113007.csv\", encoding = \"cp949\")\n",
    "area_df = area_df.drop([0,1])\n",
    "area_df = area_df.drop(columns = {\"시도(1)\", \"시군구(1)\"})\n",
    "area_df = area_df.rename(columns = {\"2020\": \"면적\"})\n",
    "year_df = year_df.reset_index(drop = True)\n",
    "area_df = area_df.reset_index(drop = True)\n",
    "\n",
    "# 2) concat\n",
    "concat_df = pd.concat([year_df, area_df], axis = 1)\n",
    "concat_df[\"면적\"] = concat_df[\"면적\"].astype(float)\n",
    "concat_df[[\"면적\"]] = concat_df[[\"면적\"]] / 1000000\n",
    "concat_df = concat_df.rename(columns = {\"면적\": \"면적:km\"})\n",
    "concat_df[\"건수\"] = concat_df[\"건수\"].astype(int)\n",
    "concat_df[\"비교\"] = concat_df[\"건수\"] / concat_df[\"면적:km\"]\n",
    "concat_df[[\"비교\"]] = concat_df[[\"비교\"]].round(0).astype(int)\n",
    "\n",
    "# 3) sort\n",
    "sort_df = concat_df.sort_values(\"비교\",ascending = False)\n",
    "\n",
    "# person 데이터 불러오기\n",
    "person = pd.read_csv(\"/Users/sangu/likelion_AIS/ais7/mid_project/person.csv\", encoding = \"cp949\")\n",
    "\n",
    "# raw 데이터 전처리\n",
    "person = person.drop(columns = {\"Unnamed: 0\"})\n",
    "person[\"총생활인구수\"] = person[\"총생활인구수\"].astype(float).round(1)\n",
    "person[\"총생활인구수\"] = person[\"총생활인구수\"].astype(int)\n",
    "person[\"총생활인구수\"].head()\n",
    "\n",
    "# 인덱싱\n",
    "person = person[[\"총생활인구수\"]]\n",
    "\n",
    "# concat\n",
    "df = pd.concat([concat_df, person], axis = 1)\n",
    "df[\"밀도\"] = df[\"총생활인구수\"] / df[\"면적:km\"]\n",
    "df[\"밀도\"] = df[\"밀도\"].round(0).astype(int)\n",
    "df.head()\n",
    "df = df.rename(columns = {\"건수\": \"가로등수\" , \"비교\": \"면적대비 가로등 비율\", \"총생활인구수\": \"인구수\", \"밀도\": \"밀도(명)\"})\n",
    "\n",
    "# sort\n",
    "sort_person = df.sort_values(\"인구수\", ascending = False)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.barplot(data = sort_person, x = \"자치구\", y = \"인구수\")\n",
    "sort_density = df.sort_values(\"밀도(명)\", ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6c1d4a9cdbc8c186d290d28fe96079660a992de7285fa4f86bc176db59ed00d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
